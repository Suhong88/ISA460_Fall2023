{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9954ae-938e-4ed4-bfb5-254897867c07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis of Global Warming Tweets on January 2023.\n",
    "This proejct is based on global warming tweets tweeted on January 2023. I have added emotion (anger, joy, opotimism and sadness) and gender at the end of each tweets. Emotion analysis was performed using a pre-trained model from Hugging Face (Twitter-roBERTa-base for Emotion Recognition). This is a roBERTa-base model trained on ~58M tweets and finetuned for emotion recognition with the TweetEval benchmark. Each tweet is classified into four emotions (joy, optimism, anger, and sadness) with a confidence score. In addition, gender is extracted based on first name of user account if a user account has a real first name and the gender can be identified by python package gender guesser. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff41ee-70b1-4c95-a0d1-5c96345127d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read tweets into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646d1f62-9544-4477-9e06-6c04918cb5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/27 18:57:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4051. Attempting port 4052.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4053. Attempting port 4054.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4054. Attempting port 4055.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting port 4056.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4056. Attempting port 4057.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4057. Attempting port 4058.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4058. Attempting port 4059.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4059. Attempting port 4060.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4060. Attempting port 4061.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4061. Attempting port 4062.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4062. Attempting port 4063.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4063. Attempting port 4064.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4064. Attempting port 4065.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4065. Attempting port 4066.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4066. Attempting port 4067.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4067. Attempting port 4068.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4068. Attempting port 4069.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4069. Attempting port 4070.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4070. Attempting port 4071.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4071. Attempting port 4072.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4072. Attempting port 4073.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4073. Attempting port 4074.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4074. Attempting port 4075.\n",
      "23/09/27 18:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4075. Attempting port 4076.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from helper_functions import displayByGroup\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check if the Spark session is active. If it is activate, close it\n",
    "\n",
    "try:\n",
    "    if spark:\n",
    "        spark.stop()\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "spark = (SparkSession.builder.appName(\"Multidimensional Data Frame\")\n",
    "        .config(\"spark.port.maxRetries\", \"100\")\n",
    "        .config(\"spark.sql.mapKeyDedupPolicy\", \"LAST_WIN\")  # This configuration allow the duplicate keys in the map data type.\n",
    "#        .config(\"spark.driver.memory\", \"16g\")\n",
    "        .getOrCreate())\n",
    "\n",
    "# confiture the log level (defaulty is WWARN)\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# read the global warming tweets\n",
    "\n",
    "df=spark.read.parquet('/opt/shared/globalwarming_202301')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c361b6-f253-4b3f-8ea2-2a9dd25153a8",
   "metadata": {},
   "source": [
    "# In class exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675df85d-1aa1-4e0c-b5b1-8685c447bab9",
   "metadata": {},
   "source": [
    "## Extract mentions of each tweet account received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "96be4cbc-2d4e-471f-9eea-7891909dc044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df.select('author').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65dd1611-b76f-4173-916c-14daee985864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mentions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- end: long (nullable = true)\n",
      " |    |    |-- start: long (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('author.entities.description.mentions').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da396ed-44f5-4d34-8033-1ecd012f8844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, desc\n",
    "df1=df.select('author.username', col('author.entities.description.mentions.username').alias('mentions')).filter(F.col('mentions').isNotNull())\n",
    "\n",
    "df2=df1.select('username', explode('mentions').alias('mentions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ad171-2fd5-48c7-bf0a-03f70e133588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users who received most mentions\n",
    "\n",
    "df2.groupBy('mentions').count().orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "48e8b21f-c8fc-4bc3-8524-eaa693741889",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:==================================================>     (58 + 6) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|       username|count|\n",
      "+---------------+-----+\n",
      "| IMPraveenDalal| 1128|\n",
      "|          _PTLB|  678|\n",
      "| _DigitalPolice|  410|\n",
      "|  FurusetGerden|  308|\n",
      "|DisasterReliefs|  306|\n",
      "|  ManishKhurana|  209|\n",
      "|         _AFPOH|  186|\n",
      "| FiyyazAhmed_06|  172|\n",
      "|  SwatiBhalla23|  151|\n",
      "|   GeraldKutney|  144|\n",
      "|       _CEDILRI|  131|\n",
      "|   HaarpDecoded|  109|\n",
      "|Qlightenigma007|   96|\n",
      "|   Living4Earth|   94|\n",
      "|     PtlbSchool|   92|\n",
      "| EastMeetsWest0|   92|\n",
      "|     jonburkeUK|   88|\n",
      "|   leon_mugisho|   79|\n",
      "|          pmagn|   79|\n",
      "|    SaleemulHuq|   78|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# user who mentioned most people\n",
    "\n",
    "df2.groupBy('username').count().orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310863c9-214f-4ed5-8340-90b281795d0a",
   "metadata": {},
   "source": [
    "## extract user location from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "327067e6-72ed-44fe-94f7-25ecd7ff63e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            location|\n",
      "+--------------------+\n",
      "| Manchester, England|\n",
      "|Down very long tr...|\n",
      "|                null|\n",
      "|Santa Ana, Califo...|\n",
      "|                null|\n",
      "|      Morgantown, WV|\n",
      "|                null|\n",
      "|                null|\n",
      "|              U.S.A.|\n",
      "|LORD HIS EXCELLEN...|\n",
      "|      Earth USA S.C.|\n",
      "|On stolen Kulin l...|\n",
      "|Rural Hall, North...|\n",
      "|Johannesburg. Sou...|\n",
      "|                null|\n",
      "|    Chicago & Galway|\n",
      "|             Germany|\n",
      "|        Alabama, USA|\n",
      "|           TOKYO-III|\n",
      "|                null|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('author.location').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54909f8-fd1d-46e0-bb39-f8dc709cb40c",
   "metadata": {},
   "source": [
    "## Extract hashtags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3c7c55f1-1acc-44b9-834e-3254fceba0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 tag|\n",
      "+--------------------+\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|[GretaThunberg, G...|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|[climate, change,...|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('entities.hashtags.tag').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba920c-4fa1-46c1-afce-9b4a1cb139d6",
   "metadata": {},
   "source": [
    "## Extract Entity (place, person, organizations) from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "423ae20c-c118-4abb-9901-bf015ca944a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|     normalized_text|          type|\n",
      "+--------------------+--------------+\n",
      "|                null|          null|\n",
      "|                null|          null|\n",
      "|[America, Pikas N...|[Place, Other]|\n",
      "|              [Elon]|      [Person]|\n",
      "|                null|          null|\n",
      "|                null|          null|\n",
      "|     [GretaThunberg]|      [Person]|\n",
      "| [Bible, Revelation]|[Other, Other]|\n",
      "|           [Florida]|       [Place]|\n",
      "|        [Ice-Age, -]|[Other, Other]|\n",
      "|                null|          null|\n",
      "|              [IPCC]|[Organization]|\n",
      "|     [MammothSteppe]|       [Place]|\n",
      "|                null|          null|\n",
      "|                null|          null|\n",
      "|[Ice Road Trucker...|[Other, Other]|\n",
      "|                null|          null|\n",
      "|    [Global Warming]|       [Other]|\n",
      "|                null|          null|\n",
      "|                null|          null|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('entities.annotations.normalized_text', 'entities.annotations.type').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "62e0a709-6bee-4b33-8cd0-22234bfec9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                 key|       value|\n",
      "+--------------------+------------+\n",
      "|             America|       Place|\n",
      "|       Pikas Now Pre|       Other|\n",
      "|                Elon|      Person|\n",
      "|       GretaThunberg|      Person|\n",
      "|               Bible|       Other|\n",
      "|          Revelation|       Other|\n",
      "|             Florida|       Place|\n",
      "|             Ice-Age|       Other|\n",
      "|                   -|       Other|\n",
      "|                IPCC|Organization|\n",
      "|       MammothSteppe|       Place|\n",
      "|Ice Road Truckers...|       Other|\n",
      "|Don’t Call It Glo...|       Other|\n",
      "|      Global Warming|       Other|\n",
      "|               Greta|      Person|\n",
      "|       GretaThunberg|      Person|\n",
      "|            Libtards|       Other|\n",
      "|         mumbo-jumbo|       Other|\n",
      "|The Age of Aquari...|       Other|\n",
      "|          Solar Myth|       Other|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=df.select(F.map_from_arrays('entities.annotations.normalized_text', 'entities.annotations.type').alias('entities'))\n",
    "\n",
    "df1.select(explode('entities')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195b384-7699-473f-a5ec-b6f6ec6d2207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Big Data Analytics",
   "language": "python",
   "name": "bigdataanalytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
