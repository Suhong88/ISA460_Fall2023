{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9954ae-938e-4ed4-bfb5-254897867c07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project three: heart disease classification\n",
    "\n",
    "## About Dataset\n",
    "Cardiovascular illnesses (CVDs) are the major cause of death worldwide. CVDs include coronary heart disease, cerebrovascular disease, rheumatic heart disease, and other heart and blood vessel problems. According to the World Health Organization, 17.9 million people die each year. Heart attacks and strokes account for more than four out of every five CVD deaths, with one-third of these deaths occurring before the age of 70. A comprehensive database for factors that contribute to a heart attack has been constructed.\n",
    "\n",
    "The main purpose here is to collect characteristics of Heart Attack or factors that contribute to it.\n",
    "The size of the dataset is 1319 samples, which have nine fields, where eight fields are for input fields and one field for an output field. Age, gender(0 for Female, 1 for Male) ,heart rate (impulse), systolic BP (pressurehight), diastolic BP (pressurelow), blood sugar(glucose), CK-MB (kcm), and Test-Troponin (troponin) are representing the input fields, while the output field pertains to the presence of heart attack (class), which is divided into two categories (negative and positive); negative refers to the absence of a heart attack, while positive refers to the presence of a heart attack.\n",
    "\n",
    "You will build a classification model to predict the presence of heart attack. As a starting point, I have built a logistics regression and a decision tree model for your reference. \n",
    "\n",
    "Please check the below site for possible classification models you can run in spark. \n",
    "[Spark MLLib for Classification](https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier)\n",
    "\n",
    "Please run at least two other algorithms for classification based on this dataset and disucss the performance of each model (using f1 score). Which model generates the best result? what features are the most important in explaining the result? In addition, try some strategies to imporve the performance of the modes and discuss your experience/lessons learned. Were you be able to imporve the performance of the model and why?\n",
    "\n",
    "## Strategy to improve the model (some may be not applicable to this dataset):\n",
    "- remove/replace outliers\n",
    "- find better ways to deal with missing values\n",
    "- add/delete/modify features, create additional features based on existing features\n",
    "- conduct hyper-parameters tuning and cross-validation\n",
    "- try different models/algorithms\n",
    "- use more data or anything else you find helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "646d1f62-9544-4477-9e06-6c04918cb5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from helper_functions import displayByGroup\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check if the Spark session is active. If it is activate, close it\n",
    "\n",
    "try:\n",
    "    if spark:\n",
    "        spark.stop()\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "spark = (SparkSession.builder.appName(\"Heart Attack Prediction\")\n",
    "        .config(\"spark.port.maxRetries\", \"200\")\n",
    "        .config(\"spark.sql.mapKeyDedupPolicy\", \"LAST_WIN\")  # This configuration allow the duplicate keys in the map data type.\n",
    "        .config(\"spark.driver.memory\", \"16g\")\n",
    "        .getOrCreate())\n",
    "\n",
    "# confiture the log level (defaulty is WWARN)\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# read the global warming tweets\n",
    "\n",
    "df=spark.read.csv('/opt/shared/Heart_Attack.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5da9113a-196f-47f9-9461-5f7adaa9dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+\n",
      "|age|gender|impluse|pressurehight|pressurelow|glucose|  kcm|troponin|   class|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+\n",
      "| 64|     1|     66|          160|         83|  160.0|  1.8|   0.012|negative|\n",
      "| 21|     1|     94|           98|         46|  296.0| 6.75|    1.06|positive|\n",
      "| 55|     1|     64|          160|         77|  270.0| 1.99|   0.003|negative|\n",
      "| 64|     1|     70|          120|         55|  270.0|13.87|   0.122|positive|\n",
      "| 55|     1|     64|          112|         65|  300.0| 1.08|   0.003|negative|\n",
      "| 58|     0|     61|          112|         58|   87.0| 1.83|   0.004|negative|\n",
      "| 32|     0|     40|          179|         68|  102.0| 0.71|   0.003|negative|\n",
      "| 63|     1|     60|          214|         82|   87.0|300.0|    2.37|positive|\n",
      "| 44|     0|     60|          154|         81|  135.0| 2.35|   0.004|negative|\n",
      "| 67|     1|     61|          160|         95|  100.0| 2.84|   0.011|negative|\n",
      "| 44|     0|     60|          166|         90|  102.0| 2.39|   0.006|negative|\n",
      "| 63|     0|     60|          150|         83|  198.0| 2.39|   0.013|negative|\n",
      "| 64|     1|     60|          199|         99|   92.0| 3.43|    5.37|positive|\n",
      "| 54|     0|     94|          122|         67|   97.0| 1.42|   0.012|negative|\n",
      "| 47|     1|     76|          120|         70|  319.0| 2.57|   0.003|negative|\n",
      "| 61|     1|     81|          118|         66|  134.0| 1.49|   0.017|positive|\n",
      "| 86|     0|     73|          114|         68|   87.0| 1.11|   0.776|positive|\n",
      "| 45|     0|     70|          100|         68|   96.0|0.606|   0.004|negative|\n",
      "| 37|     0|     72|          107|         86|  274.0| 2.89|   0.003|negative|\n",
      "| 45|     1|     60|          109|         65|   89.0|  1.6|    0.02|positive|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fdfbf95-2690-43d0-b106-9e7fb90df512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- impluse: integer (nullable = true)\n",
      " |-- pressurehight: integer (nullable = true)\n",
      " |-- pressurelow: integer (nullable = true)\n",
      " |-- glucose: double (nullable = true)\n",
      " |-- kcm: double (nullable = true)\n",
      " |-- troponin: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "25f2b205-470b-4eb4-870c-32c04301efa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+\n",
      "|age|gender|impluse|pressurehight|pressurelow|glucose|  kcm|troponin|   class|label|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+\n",
      "| 64|     1|     66|          160|         83|  160.0|  1.8|   0.012|negative|    0|\n",
      "| 21|     1|     94|           98|         46|  296.0| 6.75|    1.06|positive|    1|\n",
      "| 55|     1|     64|          160|         77|  270.0| 1.99|   0.003|negative|    0|\n",
      "| 64|     1|     70|          120|         55|  270.0|13.87|   0.122|positive|    1|\n",
      "| 55|     1|     64|          112|         65|  300.0| 1.08|   0.003|negative|    0|\n",
      "| 58|     0|     61|          112|         58|   87.0| 1.83|   0.004|negative|    0|\n",
      "| 32|     0|     40|          179|         68|  102.0| 0.71|   0.003|negative|    0|\n",
      "| 63|     1|     60|          214|         82|   87.0|300.0|    2.37|positive|    1|\n",
      "| 44|     0|     60|          154|         81|  135.0| 2.35|   0.004|negative|    0|\n",
      "| 67|     1|     61|          160|         95|  100.0| 2.84|   0.011|negative|    0|\n",
      "| 44|     0|     60|          166|         90|  102.0| 2.39|   0.006|negative|    0|\n",
      "| 63|     0|     60|          150|         83|  198.0| 2.39|   0.013|negative|    0|\n",
      "| 64|     1|     60|          199|         99|   92.0| 3.43|    5.37|positive|    1|\n",
      "| 54|     0|     94|          122|         67|   97.0| 1.42|   0.012|negative|    0|\n",
      "| 47|     1|     76|          120|         70|  319.0| 2.57|   0.003|negative|    0|\n",
      "| 61|     1|     81|          118|         66|  134.0| 1.49|   0.017|positive|    1|\n",
      "| 86|     0|     73|          114|         68|   87.0| 1.11|   0.776|positive|    1|\n",
      "| 45|     0|     70|          100|         68|   96.0|0.606|   0.004|negative|    0|\n",
      "| 37|     0|     72|          107|         86|  274.0| 2.89|   0.003|negative|    0|\n",
      "| 45|     1|     60|          109|         65|   89.0|  1.6|    0.02|positive|    1|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create label (target variable)\n",
    "\n",
    "df1=df.withColumn('label', F.when(F.col('class')==\"positive\", 1).otherwise(0))\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "10dfb112-16be-48b5-90c0-c90eba8bc40c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  810|\n",
      "|    0|  509|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5bae7a-9bfe-44e4-ac99-cec2a37421c2",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04374d9b-a3d6-408e-b79d-24aa1cef4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "#Split the model into train and test dataset\n",
    "\n",
    "(trainDF, testDF) = df1.randomSplit([.8, .2], seed=42)\n",
    "\n",
    "# we only have numerous features, and we can directly assemble all featuress into one vector\n",
    "# need to remove target varible\n",
    "numericCols = [field for (field, dataType) in df1.dtypes if (((dataType == \"double\")|(dataType == \"int\")) & (field != \"label\"))]\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "59e78953-3d18-4eca-b116-4a7c7b878b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'gender',\n",
       " 'impluse',\n",
       " 'pressurehight',\n",
       " 'pressurelow',\n",
       " 'glucose',\n",
       " 'kcm',\n",
       " 'troponin']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check numerical features and make sure it look correct\n",
    "\n",
    "numericCols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad2cb4-e7c2-4e8c-8dd7-aa46383cb507",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "018305d9-43a3-4603-a6c5-d75a0b863fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistics Regression: areaUnderROC is  0.9227418207681363\n",
      "Logistics Regression: areaUnderPR is  0.9375381601020925\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "pipeline=Pipeline(stages=[vecAssembler, lr])\n",
    "\n",
    "#train the model\n",
    "\n",
    "pipelineModel_lr=pipeline.fit(trainDF)\n",
    "\n",
    "#evaluate the model\n",
    "\n",
    "lr_predDF = pipelineModel_lr.transform(testDF)\n",
    " \n",
    "# Using areaUnderROC and areadUnderPR to evaluate binary classification model. roc is default measurement\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator()\n",
    "\n",
    "evaluator_pr=BinaryClassificationEvaluator(metricName=\"areaUnderPR\")\n",
    "\n",
    "# Evaluate logistic regression model \n",
    "\n",
    "print(\"Logistics Regression: areaUnderROC is \", evaluator_roc.evaluate(lr_predDF))\n",
    "\n",
    "print(\"Logistics Regression: areaUnderPR is \", evaluator_pr.evaluate(lr_predDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "686cc17b-4d8a-47e0-93b5-73cd5b8e3141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|age|gender|impluse|pressurehight|pressurelow|glucose|  kcm|troponin|   class|label|            features|       rawPrediction|         probability|prediction|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+--------------------+--------------------+--------------------+----------+\n",
      "| 19|     0|     70|          117|         76|   91.0|36.24|   0.025|positive|    1|[19.0,0.0,70.0,11...|[-16.928114529994...|[4.44849648021547...|       1.0|\n",
      "| 21|     0|     62|           76|         55|  111.0| 3.11|   0.003|negative|    0|[21.0,0.0,62.0,76...|[2.71461586807154...|[0.93788360377704...|       0.0|\n",
      "| 21|     1|     85|          204|         84|   93.0| 2.71|   0.002|negative|    0|[21.0,1.0,85.0,20...|[3.08493006518893...|[0.95626682720980...|       0.0|\n",
      "| 22|     1|     84|          160|         79|  102.0| 2.25|   0.006|negative|    0|[22.0,1.0,84.0,16...|[3.01327411691261...|[0.95317021730612...|       0.0|\n",
      "| 25|     1|     64|          153|         93|  110.0| 3.09|   0.097|positive|    1|[25.0,1.0,64.0,15...|[-0.3352411428759...|[0.41696592150395...|       1.0|\n",
      "| 26|     1|     54|          104|         62|   88.0|14.21|   0.004|positive|    1|[26.0,1.0,54.0,10...|[-4.1707453487215...|[0.01520595577529...|       1.0|\n",
      "| 27|     1|     94|          157|         79|  141.0| 6.25|   0.003|positive|    1|[27.0,1.0,94.0,15...|[0.49935598514473...|[0.62230797338845...|       0.0|\n",
      "| 28|     0|     96|          105|         75|  294.0| 1.45|   0.003|negative|    0|[28.0,0.0,96.0,10...|[3.22748009289885...|[0.96185540611125...|       0.0|\n",
      "| 29|     1|     76|          157|         93|  242.0| 4.79|   0.004|negative|    0|[29.0,1.0,76.0,15...|[1.04977303388081...|[0.74073131307582...|       0.0|\n",
      "| 29|     1|     81|          150|         51|  100.0| 6.48|   0.003|positive|    1|[29.0,1.0,81.0,15...|[0.51091005216495...|[0.62501978769716...|       0.0|\n",
      "| 29|     1|     84|           87|         48|  104.0| 1.58|   0.003|negative|    0|[29.0,1.0,84.0,87...|[3.05343910644338...|[0.95493077054909...|       0.0|\n",
      "| 29|     1|     89|          111|         57|   90.0| 2.89|   0.004|negative|    0|[29.0,1.0,89.0,11...|[2.30117609265328...|[0.90897439564160...|       0.0|\n",
      "| 29|     1|    108|          111|         70|  541.0|  1.5|   0.089|positive|    1|[29.0,1.0,108.0,1...|[0.57569965529669...|[0.64007729796305...|       0.0|\n",
      "| 30|     1|     60|          202|         88|  197.0|12.89|   0.003|positive|    1|[30.0,1.0,60.0,20...|[-3.3754248697352...|[0.03307238895110...|       1.0|\n",
      "| 31|     0|     81|          125|         69|  106.0|13.92|   0.008|positive|    1|[31.0,0.0,81.0,12...|[-4.0968432751525...|[0.01635320028194...|       1.0|\n",
      "| 32|     0|     40|          179|         68|  102.0| 0.71|   0.003|negative|    0|[32.0,0.0,40.0,17...|[3.89386653042358...|[0.98004006678609...|       0.0|\n",
      "| 33|     0|     63|          110|         68|  189.0| 2.52|   0.005|negative|    0|[33.0,0.0,63.0,11...|[2.38559068731899...|[0.91572190124577...|       0.0|\n",
      "| 35|     1|     66|           94|         63|  109.0| 3.71|   0.003|negative|    0|[35.0,1.0,66.0,94...|[1.37777874529075...|[0.79863402007382...|       0.0|\n",
      "| 36|     1|     63|          123|         82|  110.0| 1.57|    2.12|positive|    1|[36.0,1.0,63.0,12...|[-56.067972851945...|[4.46672051094818...|       1.0|\n",
      "| 37|     0|     72|          107|         86|  274.0| 2.89|   0.003|negative|    0|[37.0,0.0,72.0,10...|[1.80583195005848...|[0.85885737280620...|       0.0|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1f58061a-6a6d-46e5-9949-fa0617c965af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------------------------------------+-----------------------------------------+\n",
      "|label|prediction|features                                   |probability                              |\n",
      "+-----+----------+-------------------------------------------+-----------------------------------------+\n",
      "|1    |1.0       |[19.0,0.0,70.0,117.0,76.0,91.0,36.24,0.025]|[4.448496480215476E-8,0.9999999555150352]|\n",
      "|0    |0.0       |[21.0,0.0,62.0,76.0,55.0,111.0,3.11,0.003] |[0.9378836037770448,0.06211639622295517] |\n",
      "|0    |0.0       |[21.0,1.0,85.0,204.0,84.0,93.0,2.71,0.002] |[0.9562668272098092,0.043733172790190844]|\n",
      "|0    |0.0       |[22.0,1.0,84.0,160.0,79.0,102.0,2.25,0.006]|[0.953170217306127,0.046829782693872946] |\n",
      "|1    |1.0       |[25.0,1.0,64.0,153.0,93.0,110.0,3.09,0.097]|[0.41696592150395756,0.5830340784960424] |\n",
      "|1    |1.0       |[26.0,1.0,54.0,104.0,62.0,88.0,14.21,0.004]|[0.015205955775295755,0.9847940442247043]|\n",
      "|1    |0.0       |[27.0,1.0,94.0,157.0,79.0,141.0,6.25,0.003]|[0.6223079733884556,0.37769202661154444] |\n",
      "|0    |0.0       |[28.0,0.0,96.0,105.0,75.0,294.0,1.45,0.003]|[0.961855406111251,0.03814459388874902]  |\n",
      "|0    |0.0       |[29.0,1.0,76.0,157.0,93.0,242.0,4.79,0.004]|[0.7407313130758261,0.25926868692417393] |\n",
      "|1    |0.0       |[29.0,1.0,81.0,150.0,51.0,100.0,6.48,0.003]|[0.6250197876971644,0.3749802123028356]  |\n",
      "+-----+----------+-------------------------------------------+-----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predDF.select('label', 'prediction','features', 'probability').show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "118b4db7-24ac-4f17-8645-17fc69f325ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classification_performance(predDF):\n",
    "  \n",
    "  pd_prediction=predDF.select('label', 'prediction').toPandas()\n",
    "  label=pd_prediction['label']\n",
    "  pred=pd_prediction['prediction']\n",
    " \n",
    "  confusion=confusion_matrix(label, pred)\n",
    "\n",
    "  print('Confusion Matrix\\n', confusion)\n",
    "\n",
    "  print('\\nClassification Report\\n')\n",
    "\n",
    "  print(classification_report(label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f3ed3f7-11e7-4541-a862-df0727ddebd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[ 60  14]\n",
      " [ 24 128]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76        74\n",
      "           1       0.90      0.84      0.87       152\n",
      "\n",
      "    accuracy                           0.83       226\n",
      "   macro avg       0.81      0.83      0.82       226\n",
      "weighted avg       0.84      0.83      0.83       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_performance(lr_predDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "88e5880b-043a-4e56-8870-c5dc4ebfe75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# option 1: extract feature importance\n",
    "\n",
    "# define a function to return feature names for logisitcs regression\n",
    "def feature_names(df, features):\n",
    "  featureIndex=df.schema[features].metadata[\"ml_attr\"][\"attrs\"]\n",
    " \n",
    "  feature_names=[]\n",
    "  # print numeric feature\n",
    "  for x in range(len(df.schema[features].metadata[\"ml_attr\"][\"attrs\"]['numeric'])):\n",
    "    try:\n",
    "      feature_names.append(featureIndex[\"numeric\"][x]['name'])\n",
    "    except:\n",
    "      continue\n",
    " # print binary feature\n",
    "  try:\n",
    "      for x in range(len(df.schema[features].metadata[\"ml_attr\"][\"attrs\"]['binary'])):\n",
    "        try:\n",
    "           feature_names.append(featureIndex[\"binary\"][x]['name'])\n",
    "        except:\n",
    "          continue\n",
    "  except:\n",
    "     return feature_names\n",
    "\n",
    "# feature importance\n",
    "def lr_coefficients(df, model, features=\"features\"):\n",
    "  coefficients =model.coefficients\n",
    "  names=feature_names(df, features)\n",
    " \n",
    "  weightsDF = pd.DataFrame(zip(name, coefficients, list(map(abs, coefficients))), columns=['feature', 'weights', 'abs_weights'])\n",
    "  sorted_list=weightsDF.sort_values('abs_weights', ascending=False)[['feature', 'weights']]\n",
    "  return sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fe2eac01-6044-414c-bb05-02c596c8f009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlr_coefficients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_predDF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipelineModel_lr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[125], line 29\u001b[0m, in \u001b[0;36mlr_coefficients\u001b[0;34m(df, model, features)\u001b[0m\n\u001b[1;32m     26\u001b[0m coefficients \u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcoefficients\n\u001b[1;32m     27\u001b[0m names\u001b[38;5;241m=\u001b[39mfeature_names(df, features)\n\u001b[0;32m---> 29\u001b[0m weightsDF \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mzip\u001b[39m(\u001b[43mname\u001b[49m, coefficients, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mabs\u001b[39m, coefficients))), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_weights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     30\u001b[0m sorted_list\u001b[38;5;241m=\u001b[39mweightsDF\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_weights\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sorted_list\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "lr_coefficients(lr_predDF, pipelineModel_lr.stages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a25df7d3-bea9-41c7-b21b-b029c7533935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troponin</td>\n",
       "      <td>27.671303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kcm</td>\n",
       "      <td>0.577681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.247278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.053819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pressurelow</td>\n",
       "      <td>0.010215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pressurehight</td>\n",
       "      <td>-0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impluse</td>\n",
       "      <td>-0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glucose</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  coefficient\n",
       "7       troponin    27.671303\n",
       "6            kcm     0.577681\n",
       "1         gender     0.247278\n",
       "0            age     0.053819\n",
       "4    pressurelow     0.010215\n",
       "3  pressurehight    -0.005063\n",
       "2        impluse    -0.000221\n",
       "5        glucose     0.000106"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option 2: extract feature importance\n",
    "\n",
    "feature_names=pipelineModel_lr.stages[0].getInputCols()\n",
    "coefficients=pipelineModel_lr.stages[1].coefficients\n",
    "\n",
    "weightsDF = pd.DataFrame(zip(feature_names, coefficients, list(map(abs, coefficients))), columns=['feature', 'coefficient', 'abs_coefficient'])\n",
    "sorted_list=weightsDF.sort_values('abs_coefficient', ascending=False)[['feature', 'coefficient']]\n",
    "\n",
    "sorted_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7329d2-26b7-4065-8754-7fd1f276f963",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c1d05ca-ff3f-4475-a25c-b383c690447d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot recognize a pipeline stage of type <class 'list'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m pipeline\u001b[38;5;241m=\u001b[39mPipeline(stages\u001b[38;5;241m=\u001b[39m[vecAssembler, dt])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#train the model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pipelineModel_dt\u001b[38;5;241m=\u001b[39m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainDF\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#evaluate the model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m dt_predDF \u001b[38;5;241m=\u001b[39m pipelineModel_dt\u001b[38;5;241m.\u001b[39mtransform(testDF)\n",
      "File \u001b[0;32m/home/pssclabs/.conda/envs/BigDataAnalytics/lib/python3.10/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/home/pssclabs/.conda/envs/BigDataAnalytics/lib/python3.10/site-packages/pyspark/ml/pipeline.py:122\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m stages:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(stage, Estimator) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stage, Transformer)):\n\u001b[0;32m--> 122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot recognize a pipeline stage of type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(stage))\n\u001b[1;32m    123\u001b[0m indexOfLastEstimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stages):\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot recognize a pipeline stage of type <class 'list'>."
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", seed=42)\n",
    "\n",
    "pipeline=Pipeline(stages=[vecAssembler, dt])\n",
    "\n",
    "#train the model\n",
    "\n",
    "pipelineModel_dt=pipeline.fit(trainDF)\n",
    "\n",
    "#evaluate the model\n",
    "\n",
    "dt_predDF = pipelineModel_dt.transform(testDF)\n",
    " \n",
    "# Using areaUnderROC and areadUnderPR to evaluate binary classification model. roc is default measurement\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator()\n",
    "\n",
    "evaluator_pr=BinaryClassificationEvaluator(metricName=\"areaUnderPR\")\n",
    "\n",
    "# Evaluate logistic regression model \n",
    "\n",
    "print(\"Decision Tree: areaUnderROC is \", evaluator_roc.evaluate(dt_predDF))\n",
    "\n",
    "print(\"Deccision Tree: areaUnderPR is \", evaluator_pr.evaluate(dt_predDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3e3690ce-53ac-472f-8b98-57ed11ebfaa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_115380d19d7b, depth=5, numNodes=23, numClasses=2, numFeatures=8\n"
     ]
    }
   ],
   "source": [
    "treeModel = pipelineModel_dt.stages[-1]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3ad7826-7007-47fd-80b2-19fac9744153",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[ 60  14]\n",
      " [ 24 128]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76        74\n",
      "           1       0.90      0.84      0.87       152\n",
      "\n",
      "    accuracy                           0.83       226\n",
      "   macro avg       0.81      0.83      0.82       226\n",
      "weighted avg       0.84      0.83      0.83       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_performance(dt_predDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40c933ad-c54b-4922-951d-35f15e1b64b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check feature importance for the tree baded model without ohe\n",
    "def dt_featureImportance_no_ohe(model, vecAssembler):\n",
    "    featureImp = pd.DataFrame(\n",
    "        list(zip(vecAssembler.getInputCols(), model.featureImportances)),\n",
    "      columns=[\"feature\", \"importance\"])\n",
    "    return featureImp.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "30fd9c8b-f192-4d42-a15a-82ffc3c90d08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troponin</td>\n",
       "      <td>0.616069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kcm</td>\n",
       "      <td>0.353566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.021114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.005510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pressurehight</td>\n",
       "      <td>0.003741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impluse</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pressurelow</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glucose</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "7       troponin    0.616069\n",
       "6            kcm    0.353566\n",
       "1         gender    0.021114\n",
       "0            age    0.005510\n",
       "3  pressurehight    0.003741\n",
       "2        impluse    0.000000\n",
       "4    pressurelow    0.000000\n",
       "5        glucose    0.000000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtModel=pipelineModel_dt.stages[1]\n",
    "vecAssembler=pipelineModel_dt.stages[0]\n",
    "\n",
    "dt_featureImportance_no_ohe(dtModel, vecAssembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41f742-11eb-4661-9555-883792e04e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Big Data Analytics",
   "language": "python",
   "name": "bigdataanalytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
